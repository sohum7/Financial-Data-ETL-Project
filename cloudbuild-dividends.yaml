steps:
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: 'Deploy Cloud Function'
    entrypoint: bash
    args:
      - -c
      - |
        echo "**** Uploading Cloud Function source code... ****"
        if gcloud functions deploy market-stack-dividends-extract \
          --gen2 \
          --runtime=python310 \
          --region=us-central1 \
          --service-account=market-stack-func-gcs-uploader@project-e6aecb7b-2aa0-4815-8c3.iam.gserviceaccount.com \
          --entry-point=extract_entry_point \
          --source=dividends \
          --allow-unauthenticated \
          --trigger-http \
          --timeout=720s;
        then
          echo "Cloud Function deployed successfully."
        else
          echo "Failed to deploy Cloud Function."
          exit 1
        fi

  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: 'Upload PySpark Job'
    entrypoint: bash
    args:
      - -c
      - |
        echo "**** Copying transfer.py to GCS bucket... ****"
        if gsutil cp dividends/code/transform.py gs://market-stack-code-dev/dataproc/dividends/transform.py;
        then
          echo "File copied successfully."
        else
          echo "Failed to copy file."
          exit 1
        fi

options:
  logging: CLOUD_LOGGING_ONLY